{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhxMVBzp/48dnYylwGoZpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanPabloAbril/healthy-skin-Team/blob/main/healthySkinTeam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1>Healthy Skin Team </h1>"
      ],
      "metadata": {
        "id": "LDCm68K0wPd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JuanPabloAbril/healthy-skin-Team.git\n",
        "\n"
      ],
      "metadata": {
        "id": "V9cPfYzYBBn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b76aeed-8101-4753-ad9c-b5653030dcb9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'healthy-skin-Team' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "M_v2-1kvuxTT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tamaño de las imágenes y el batch size"
      ],
      "metadata": {
        "id": "U1dscPBUvVTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = 224, 224\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "1U4f5u0rvVyk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
      ],
      "metadata": {
        "id": "QDXhamjFvgej"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validar el total de las imagenes y el total de las clases\n"
      ],
      "metadata": {
        "id": "6Aau328XwH4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/healthy-skin-Team/Entrenamiento',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzQgC21-vizs",
        "outputId": "983a1f83-4346-4c41-be97-10ffef3c4c6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1795 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/healthy-skin-Team/Entrenamiento',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh1wLHBCw6VI",
        "outputId": "bc1b9750-7537-4dad-ef7f-b4b4402eb209"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 444 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Modelo CNN </h1>"
      ],
      "metadata": {
        "id": "s-rpHuhsyib_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "9g2AIYBPykQA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(9, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "KWfeNkB4ytcm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Compilación del modelo  </h2>"
      ],
      "metadata": {
        "id": "gtIhfah-yzCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PUPFqtobyzWL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Entrenamiento del modelo </h2>"
      ],
      "metadata": {
        "id": "CQiIvrAMy9ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0FznU19y86x",
        "outputId": "30209bef-41b2-4053-b765-6fd11b4e91ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 251s 4s/step - loss: 2.2387 - accuracy: 0.2479 - val_loss: 1.8097 - val_accuracy: 0.3198\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 246s 4s/step - loss: 1.8570 - accuracy: 0.3298 - val_loss: 1.9321 - val_accuracy: 0.3311\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 257s 4s/step - loss: 1.6534 - accuracy: 0.4162 - val_loss: 1.8900 - val_accuracy: 0.3536\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 247s 4s/step - loss: 1.5457 - accuracy: 0.4630 - val_loss: 1.6440 - val_accuracy: 0.4527\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 256s 5s/step - loss: 1.4555 - accuracy: 0.4919 - val_loss: 1.9486 - val_accuracy: 0.3851\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 245s 4s/step - loss: 1.3740 - accuracy: 0.5265 - val_loss: 1.7749 - val_accuracy: 0.4189\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 253s 4s/step - loss: 1.2772 - accuracy: 0.5543 - val_loss: 1.8045 - val_accuracy: 0.3986\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 248s 4s/step - loss: 1.2325 - accuracy: 0.5599 - val_loss: 2.1427 - val_accuracy: 0.4527\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 245s 4s/step - loss: 1.1730 - accuracy: 0.5805 - val_loss: 2.1729 - val_accuracy: 0.4257\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 252s 4s/step - loss: 1.0531 - accuracy: 0.6306 - val_loss: 2.3391 - val_accuracy: 0.4144\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 247s 4s/step - loss: 1.1367 - accuracy: 0.5983 - val_loss: 2.0931 - val_accuracy: 0.4347\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 255s 4s/step - loss: 0.9664 - accuracy: 0.6691 - val_loss: 1.9479 - val_accuracy: 0.4257\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 246s 4s/step - loss: 0.9449 - accuracy: 0.6802 - val_loss: 2.4719 - val_accuracy: 0.4392\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 247s 4s/step - loss: 0.8778 - accuracy: 0.6981 - val_loss: 2.1739 - val_accuracy: 0.4302\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 257s 5s/step - loss: 0.8397 - accuracy: 0.7047 - val_loss: 2.0286 - val_accuracy: 0.4505\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 247s 4s/step - loss: 0.7994 - accuracy: 0.7214 - val_loss: 2.8623 - val_accuracy: 0.4369\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 253s 4s/step - loss: 0.7072 - accuracy: 0.7532 - val_loss: 3.2178 - val_accuracy: 0.4505\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 249s 4s/step - loss: 0.6486 - accuracy: 0.7788 - val_loss: 2.6107 - val_accuracy: 0.4392\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 249s 4s/step - loss: 0.5779 - accuracy: 0.7989 - val_loss: 3.4584 - val_accuracy: 0.4189\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 254s 4s/step - loss: 0.5459 - accuracy: 0.8173 - val_loss: 3.0485 - val_accuracy: 0.4369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluación del modelo\n"
      ],
      "metadata": {
        "id": "JL5wie0gGjSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f'Pérdida: {loss}, Precisión: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBd-cdYeGlVJ",
        "outputId": "f0511fd4-0851-4fab-892e-bcef63eb944a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 18s 1s/step - loss: 3.0485 - accuracy: 0.4369\n",
            "Pérdida: 3.0485036373138428, Precisión: 0.4369369447231293\n"
          ]
        }
      ]
    }
  ]
}